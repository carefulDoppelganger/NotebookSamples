{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to collect Daily Prices and Sentiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from pandas import json_normalize\n",
    "import glob\n",
    "import ast "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining API Key and Companies to review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '6CDMRKZS34KKOJV8'\n",
    "companies = ['AMZN','GOOGL','AAPL','MSFT','NVDA'] # List of companies should be updated (5 companies per minute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting Daily Prices data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 'DAILY'\n",
    "dailyPricesData = pd.DataFrame()\n",
    "for ticker in companies: # Change range of values because we can only retrieve data of 5 companies with the free API key\n",
    "    # Getting data for each ticker\n",
    "    dailyDataTicker = requests.get(f\"https://www.alphavantage.co/query?function=TIME_SERIES_{duration}&symbol={ticker}&apikey={api_key}&outputsize=full\").json()\n",
    "    # Converting data in a Data Frame\n",
    "    dailyDataTicker = pd.DataFrame(dailyDataTicker['Time Series (Daily)']).transpose().reset_index().rename(columns={'index': 'date'})\n",
    "    # Adding column with Ticker name\n",
    "    dailyDataTicker['TickerName'] = ticker\n",
    "    # Adding Data Frame to monthly data\n",
    "    dailyPricesData = pd.concat([dailyPricesData, dailyDataTicker], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data frame\n",
    "dailyPricesData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data frame as csv file\n",
    "dailyPricesData.to_csv('DailyPricesTechCompanies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Getting News & Sentiment data\n",
    "\n",
    "Topics covered in this script: ipo, technology, and earnings. We need to run the same code for each topic. More topics could be add if required. See: https://www.alphavantage.co/documentation/#news-sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Score definition:\n",
    "\n",
    "x <= -0.35          : Bearish\n",
    "\n",
    "-0.35 < x <= -0.15  : Somewhat-Bearish\n",
    "\n",
    "-0.15 < x < 0.15    : Neutral\n",
    "\n",
    "0.15 <= x < 0.35    : Somewhat_Bullish\n",
    "\n",
    "x >= 0.35           : Bullish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty List\n",
    "sentimentData = list()\n",
    "# Getting News & Sentiment for compnaies\n",
    "for ticker in companies:\n",
    "    # Getting overview of each compnay\n",
    "    #url = f'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={ticker}&apikey={api_key}&limit=1000&sort=LATEST&topics=ipo'\n",
    "    #url = f'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={ticker}&apikey={api_key}&limit=1000&sort=LATEST&topics=technology'\n",
    "    url = f'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={ticker}&apikey={api_key}&limit=1000&sort=LATEST&topics=earnings'\n",
    "    urlContent = requests.get(url).json()\n",
    "    # Adding dictionary to list\n",
    "    sentimentData.append(urlContent)\n",
    "# Creating data frame with list\n",
    "sentimentNews = pd.DataFrame(sentimentData)\n",
    "# Removing companies without articles\n",
    "sentimentNews = sentimentNews[sentimentNews['items'] != '0']\n",
    "# For each line, feed has a list of dictionaries.\n",
    "# Each dicitonary represents an article. We will create a row per article\n",
    "sentimentNews = sentimentNews.explode('feed')\n",
    "sentimentNews.reset_index(drop=True,inplace=True)\n",
    "# The key of each dictionary describes a feature. We will create a new column for each dictionary key\n",
    "feedData = pd.json_normalize(sentimentNews['feed'])\n",
    "sentimentNews = pd.concat([sentimentNews,feedData], axis=1).drop(['feed','items',\n",
    "                                                                  'sentiment_score_definition',\n",
    "                                                                  'relevance_score_definition'], axis=1)\n",
    "# Even though the API provides us with an overall sentiment score and label columns,\n",
    "# column ticker_sentiment contains a list of dictionaries with sentiment scores and labels per company.\n",
    "# First, we will create a column to record the number of companies related to the article\n",
    "sentimentNews['numberOfCompanies'] = sentimentNews.apply(lambda row: len(row['ticker_sentiment']), axis=1)\n",
    "# Creating a row per company (Dictionary)\n",
    "sentimentNews = sentimentNews.explode('ticker_sentiment')\n",
    "sentimentNews.reset_index(drop=True,inplace=True)\n",
    "# Expanding keys of dictionaries\n",
    "tickerSentimentData = pd.json_normalize(sentimentNews['ticker_sentiment'])\n",
    "sentimentNews = pd.concat([sentimentNews,tickerSentimentData], axis=1).drop(['ticker_sentiment'], axis=1)\n",
    "sentimentNews = sentimentNews.rename(columns={'ticker':'companyName',\n",
    "                                              'relevance_score':'companyRelevanceScore',\n",
    "                                              'ticker_sentiment_score':'companySentimentScore',\n",
    "                                              'ticker_sentiment_label':'companySentimentLabel'})\n",
    "# Each article is related to different topics\n",
    "# Let's create a row per topic\n",
    "sentimentNews = sentimentNews.explode('topics')\n",
    "sentimentNews.reset_index(drop=True,inplace=True)\n",
    "# Let's create a column for the topic and topic relevance score\n",
    "topicData = pd.json_normalize(sentimentNews['topics'])\n",
    "sentimentNews = pd.concat([sentimentNews,topicData], axis=1).drop(['topics','authors'], axis=1)\n",
    "sentimentNews = sentimentNews.rename(columns={'relevance_score':'topicRelevanceScore'})\n",
    "# Since more than one company can be related to the article, let's remove duplicate rows\n",
    "sentimentNews = sentimentNews.drop_duplicates()\n",
    "sentimentNews.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data frame as csv file\n",
    "sentimentNews.to_csv('SentimentNewsTechCompanies.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
